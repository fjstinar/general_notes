[[RESULTS_UNDERGRAD]]
### 11/22/24


Dataset:
H: One different grade prediction dataset...

Method:
H: Logistic regression/random forest also use SVM models
F: Switch to only preprocessing -> use ~4 methods.
F: One can be SMOTE

Result:
F: Accuracy, AUC. Overall and per group before/after mitigation

F: Statistical significance? Bootstrapping the confidence intervals?






### 10/22/24
What the poster needs:
- motivation
- research questions
- data
	- data provenance
	- what are the sensitive groups
		- proportion of the two groups
		- proportion of positive outcome for each group
- methods
	- pipeline diagram
- results
	- Adversial Debiasing
- 


### Hanning
Last year
- Went over the ideas of algorithmic fairness
- Used the AIF360 package to go through Reweighing on the student-math data
	- Logistic Regression
	- Random Forest
- Student math performance dataset was the final point of the research week

What does she want this year:
	-complete/comprehensive project | turn it into a paper about this previous work
	-

Next steps
	 - Combine these steps with a few other methods for a research paper to be submitted
	 - Share the unfairness mitigation code with Hanning...

Next week
 - Find educational datasets you would be interested in/think are useful




Research showcase is useful... Fill that out form

https://archive.ics.uci.edu/dataset/856/higher+education+students+performance+evaluation

https://www.kaggle.com/datasets/rabieelkharoua/students-performance-dataset?resource=download

https://www.kaggle.com/datasets/mylesoneill/world-university-rankings?select=cwurData.csv


 - Choose unfairness mitigation methods
	 - Preprocessing method
		 - 
	 - Inprocessing method
		 - 
	 - Postprocessing method

Official ways to continue doing things


Continue with PhD

Letter of Recommendation - Curious

Letter of rec for grad student I am working with. Let me ask how Nigel want to handle that...

Nigel Bosch letter of rec

Applying to programs within this school...

Are we hiring research assistants outside of student-ship?

Possibly research showcase


#### PROJECT OUTLINE

##### Initial Paper
**RQ1**: *Do demographic differences in standardized assessment scores correspond to biases in machine learning models?*

**RQ2**: *What are the implications of machine learning unfairness mitigation methods when applied to student test score prediction?*

Make document of results


We can turn the current research into a "where can unfairness mitigation fail for educational data" paper.

We would need specific examples of how the unfairness mitigation strategy impacted data and led to some type of fairer model, but an implication seems wrong because of this.

Make sure we could extend papers. PPR vs Accuracy. Could find that the fairness definitions are incompatible in education.

Explore the tradeoff in education research

Could say how big is the tradeoff/gap and given the average gap between the accuracy/base rates could simulate a what-if the benefit of predicting mastery is X amount relative to the benefit of predicting accuracy.


Simulated Data - https://www.kaggle.com/datasets/rabieelkharoua/students-performance-dataset/data


**Are you taking students???**
**Very low chance?**
Nigel apparently you are very popular

Change to py script and cross validate...
Possibly move away from binary classification...
Do this by this evening...


Datasets:

Kaggle synthetic information
Higher Education Reweighing



### Jocelyn

- No library science/MSLIS
- 
